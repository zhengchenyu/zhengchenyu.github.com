<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>机器学习-2.4-监督学习之softmax | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="Softmax Regression下面介绍一下指数族分布的另外一个例子。之前的逻辑回归中，可以用来解决二分类的问题。对于有k中可能结果的时候，问题就转化为多分类问题了，也就是接下来要说明的softmax regression问题。s 1 函数定义在进行下一步推导前，我们先定义部分辅助函数。我们这里事先定义一个k-1维向量\(T(y)\)，这里具体对应于指数族分布的\(T(y)\),具体定义如">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习-2.4-监督学习之softmax">
<meta property="og:url" content="http://example.com/2017/07/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-2-4-%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%B9%8Bsoftmax/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="Softmax Regression下面介绍一下指数族分布的另外一个例子。之前的逻辑回归中，可以用来解决二分类的问题。对于有k中可能结果的时候，问题就转化为多分类问题了，也就是接下来要说明的softmax regression问题。s 1 函数定义在进行下一步推导前，我们先定义部分辅助函数。我们这里事先定义一个k-1维向量\(T(y)\)，这里具体对应于指数族分布的\(T(y)\),具体定义如">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-softmax%E6%A0%B7%E6%9C%AC.png">
<meta property="og:image" content="http://example.com/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-softmax%E8%AE%A1%E7%AE%97%E7%BB%93%E6%9E%9C.png">
<meta property="og:image" content="http://example.com/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-softmax%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC%E6%89%8B%E5%86%99%E7%89%881.png">
<meta property="og:image" content="http://example.com/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-softmax%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC%E6%89%8B%E5%86%99%E7%89%882.png">
<meta property="og:image" content="http://example.com/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-softmax%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC%E6%89%8B%E5%86%99%E7%89%883.png">
<meta property="article:published_time" content="2017-07-24T10:35:50.000Z">
<meta property="article:modified_time" content="2025-02-07T08:06:18.199Z">
<meta property="article:author" content="zhengchenyu">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-softmax%E6%A0%B7%E6%9C%AC.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-机器学习-2-4-监督学习之softmax" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2017/07/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-2-4-%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%B9%8Bsoftmax/" class="article-date">
  <time class="dt-published" datetime="2017-07-24T10:35:50.000Z" itemprop="datePublished">2017-07-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      机器学习-2.4-监督学习之softmax
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <script type="text/javascript" src="/Users/zcy/Desktop/study/git/MathJax-master/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<h1 id="Softmax-Regression"><a href="#Softmax-Regression" class="headerlink" title="Softmax Regression"></a>Softmax Regression</h1><p>下面介绍一下指数族分布的另外一个例子。之前的逻辑回归中，可以用来解决二分类的问题。对于有k中可能结果的时候，问题就转化为多分类问题了，也就是接下来要说明的softmax regression问题。<br>s</p>
<h2 id="1-函数定义"><a href="#1-函数定义" class="headerlink" title="1 函数定义"></a>1 函数定义</h2><p>在进行下一步推导前，我们先定义部分辅助函数。我们这里事先定义一个k-1维向量\(T(y)\)，这里具体对应于指数族分布的\(T(y)\),具体定义如下:</p>

$$T(1) = \left[ \begin{gathered}  1 \hfill \\\  0 \hfill \\\  0 \hfill \\\  ... \hfill \\\  0 \hfill \\ \end{gathered}  \right],T(2) = \left[ \begin{gathered}  0 \hfill \\\  1 \hfill \\\  0 \hfill \\\  ... \hfill \\\  0 \hfill \\ \end{gathered}  \right],T(3) = \left[ \begin{gathered}  0 \hfill \\\  0 \hfill \\\  1 \hfill \\\  ... \hfill \\\  0 \hfill \\\ \end{gathered}  \right],...,T(k - 1) = \left[ \begin{gathered}  0 \hfill \\\  0 \hfill \\\  0 \hfill \\\  ... \hfill \\\  1 \hfill \\ \end{gathered}  \right],T(k) = \left[ \begin{gathered}  0 \hfill \\\  0 \hfill \\\  0 \hfill \\\  ... \hfill \\\  0 \hfill \\ \end{gathered}  \right]$$


<p>我们定义\(T(y) _1\)表示的\(T(y)\)第一个元素，其他依次类推。</p>
<p>然后再引入一个函数，具体定义如下:</p>
$$1\{ true\} = 1$$
$$1\{ false\} = 0$$

<blockquote>
<p>可以通过带入值的方式验证上式。</p>
</blockquote>
<h2 id="2模型推导"><a href="#2模型推导" class="headerlink" title="2	模型推导"></a>2	模型推导</h2><p>在softmax中,我们知道\(y \in \{ 1,2,…,k\}\)。我们设置\(y&#x3D;1\)的概率为\(\phi _1\),<br>类似的有\(y&#x3D;k\)的概率为\(\phi _k\)，并且我们轻易得到如下公式：</p>
$$\sum\limits _{i = 1}^k {\phi _i}  = 1$$$${\phi _k} = \sum\limits _{i = 1}^{k - 1}{\phi _i}$$


<p>由于我们已经知道\(p(y &#x3D; i) &#x3D; {\phi _i}\)，综上可以得到:</p>

$$p(y) = \phi _1^{1\{ y = 1\} }\phi _2^{1\{ y = 2\} }...\phi _k^{1\{ y = k\} } = \phi _1^{1\{ y = 1\} }\phi _2^{1\{ y = 2\} }...\phi _k^{1 - \sum\limits _{i = 1}^{k - 1} {1\{ y = i\} } } = \phi _1^{T{(y)} _1}\phi _2^{T{{(y)} _2}}...\phi _k^{1 - \sum\limits _{i = 1}^{k - 1} {T{(y)} _i} }$$$$p(y) = \exp (T{(y) _1}\ln {\phi _1} + T{(y) _2}\ln {\phi _2} + ... + (1 - \sum\limits _{i = 1}^{k - 1} {T{{(y)} _i}} )\ln {\phi _k})$$$$p(y) = \exp (T{(y) _1}\ln \frac{\phi _1}{\phi _k} + T{(y) _2}\ln \frac{\phi _2}{\phi _k} + ... + T{(y) _{k - 1}}\ln \frac{\phi _{k - 1}}{\phi _k} + \ln {\phi _k})$$


<p>我们对照指数族分布，其中\(T(y)\)我们已经定义，可以得到其他参数如下:</p>

$$b(y) = 1$$
$$a(\eta ) =  - \ln {\phi _k}$$
$$\eta  = \left[ \begin{gathered}  \ln \frac{\phi _1}{\phi _k} \hfill \\\  \ln \frac{\phi _2}{\phi _k} \hfill \\\  ... \hfill \\\  \ln \frac{\phi _{k - 1}}{\phi _k} \hfill \\\ \end{gathered}  \right]$$


<p>我们用\(\eta\)来表示\(\phi\)，目标是将我们的问题归整为一个变量的问题，从而更容易计算。对上面向量拆开计算得到:</p>

$${\eta _i} = \ln \frac{\phi _i}{\phi _k}$$


<p>继而可以转化为:</p>

$${\eta _i} = \ln \frac{\phi _i}{\phi _k}$$


<p>又由于我们已知\(\sum\limits _{j &#x3D; 1}^k {\phi _j}  &#x3D; 1\)，所以有:</p>

$$\sum\limits _{i = 1}^k {e^{\eta _i}{\phi _k}}  = 1$$


<p>继而有:</p>

$${\phi _k} = \frac{1}{\sum\limits _{j = 1}^k {e^{\eta _j}}}$$


<p>最后我们可以得到:</p>

$${\phi _i} = \frac{e^{\eta _i}}{\sum\limits _{j = 1}^k {e^{\eta _j}}}$$


<p>由于指数组分布假设是关于输入的线性函数，所以得到在已知\(x\)和\(\theta\)的情况下\(y&#x3D;i\)的概率的公式，如下：</p>
$$p(y = i|x,\theta ) = {\phi _i} = \frac{e^{\eta _i}}{\sum\limits _{j = 1}^k {e^{\eta _j}}} = \frac{e^{\theta _i^Tx}}{\sum\limits _{j = 1}^k {e^{\theta _j^Tx}}}$$


<p>这里我们可以得到\({h_\theta }(x)\),如下:</p>
$${h_\theta }(x) = E[T(y)|x,\theta ] = E[\left( \begin{gathered}  1\{ y = 1\}  \hfill \\\  1\{ y = 2\}  \hfill \\\  ... \hfill \\\  1\{ y = k - 1\}  \hfill \\\ \end{gathered}  \right)|x,\theta ]$$

$${h_ \theta }(x) = E[\left( \begin{gathered}  {\phi _1} \hfill \\\  {\phi _2} \hfill \\\  ... \hfill \\\  {\phi _{k - 1}} \hfill \\\ \end{gathered}  \right)|x,\theta ] = \left( \begin{gathered}  \frac{e^{\theta _1^Tx}}{\sum\limits _{j = 1}^k {e^{\theta  _j^Tx}}} \hfill \\\  \frac{e^{\theta _2^Tx}}{\sum\limits _{j = 1}^k {e^{\theta _j^Tx}}} \hfill \\\  ... \hfill \\\  \frac{e^{\theta _{k - 1}^Tx}}{\sum\limits _{j = 1}^k {e^{\theta _j^Tx}}} \hfill \\\\end{gathered}  \right)$$


<blockquote>
<p>其中,\(k\)为取值的可能集合的大小，\(\theta\)为一个\(k*n\)的矩阵。</p>
</blockquote>
<p>到这里我们可以定义我们的损失函数了，如下:</p>
$$J(x) = \frac{1}{2}\sum\limits _{i = 1}^m {{(T(y) - {h _\theta }(x))}^2}$$


<p>上式是一个向量，我们可以对这个向量继续求平方和，来衡量准确度，如下：</p>
$$J(x) = \frac{1}{2}\sum\limits _{i = 1}^m {|{{(T(y) - {h _\theta }(x))}^2}|}$$


<p>损失函数已经定义完成，我们就有了算法的截止条件了。接下来就是找到算法的最优迭代方向，也就是计算其偏导数了。</p>
<p>我们使用最大释然性来计算迭代方向。建模的原则是：对于一个已知\(y&#x3D;i\)的样本\((x,y)\)，我们需要找到一个方向去迭代\(\theta\)，使得\(\phi _i\)尽可能大，使得其他\(\phi\)尽可能小。当然由于所有\(\phi\)之和为1,所以我们只需要保证\(\phi _i\)尽可能大即可。因此,在已经的\(m\)个样本的情况下，我们只需要保证下面的式子最大:</p>

$$\sum\limits _{i = 1}^m {p(y = {y^i}|x,\theta )}  = \sum\limits _{i = 1}^m {\prod\limits _{l = 1}^k {p{(y = l|x,\theta )}^{1\{ {y^i} = l\}}} }$$


<p>取自然对数后，我们定义最大似然函数:</p>

$$l(\theta ) = \sum\limits _{i = 1}^m {\ln \prod\limits _{l = 1}^k {(\frac{e^{\theta _l^Tx}}{\sum\limits _{j = 1}^k {e^{\theta _j^Tx}}})^{1\{{y^i} = l\}}}}$$

<p>当且仅当\({y^i} &#x3D; l\)的时候, \(^{1{y^i&#x3D;l\} &#x3D; 1})。其他值为0，我们可以将连乘转化，如下：</p>
$$l(\theta ) = \sum\limits _{i = 1}^m {\ln (\frac{e^{\theta _{y^i}^Tx}}{\sum\limits _{j = 1}^k {e^{\theta _j^Tx}}})}  = \sum\limits _{i = 1}^m {\ln [\theta _{y^i}^Tx - \ln \sum\limits _{j = 1}^k {e^{\theta _j^Tx}}]} $$


<p>然后对其求偏导数,对\(y _i&#x3D;f\)的时候后有：</p>
$$\frac{\partial l(\theta )}{\partial {\theta _f}} = \sum\limits _{i = 1}^m {\ln [{x _f} - \frac{e^{\theta _f^Tx}{x _f}}{\sum\limits _{j = 1}^k {e^{\theta _j^Tx}}}]}$$


<p>对\({y_i} \ne f\)的时候，有：</p>
$$\frac{\partial l(\theta )}{\partial {\theta _f}} = \sum\limits _{i = 1}^m {\ln [0 - \frac{e^{\theta _f^Tx}{x _f}}{\sum\limits _{j = 1}^k {e^{\theta _j^Tx}}}]}$$


<p>综上，可以得到:</p>
$$\frac{\partial l(\theta )}{\partial {\theta _f}} = \sum\limits _{i = 1}^m {\ln [1\{ {y^i} = f\}  - \frac{e^{\theta _f^Tx}}{\sum\limits _{j = 1}^k {e^{\theta _j^Tx}}}]{x _f}}  = \sum\limits _{i = 1}^m {\ln [1\{{y^i} = f\}  - {\phi _f}]{x _f}}$$


<blockquote>
<p>\(x _f\)是一个向量，因为公式一次迭代更新一个维度下的一组\(\theta\)。事实上，这里是一个向量求微分。如果我们对的某个元素\(\theta\)进行微分，我们依然能够得到这个公式。</p>
</blockquote>
<h2 id="3-实际问题的解决"><a href="#3-实际问题的解决" class="headerlink" title="3 实际问题的解决"></a>3 实际问题的解决</h2><p>我们随机制造一组数据，在\(2*2\)的空间内使用直线\({x _2} &#x3D; 0.5*{x _1}\)和直线\({x _2} &#x3D; -0.5*{x _1}+2\)具体的分类如下:</p>
<img src="/images/机器学习/监督学习-softmax样本.png" width=50% height=50% text-align=center/>

<p>根据之前的推导，编写如下代码:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> matplotlib.lines <span class="keyword">import</span> Line2D</span><br><span class="line"></span><br><span class="line">g_x_arr=[[<span class="number">1</span>, <span class="number">0.035</span>, <span class="number">1.344</span>], [<span class="number">1</span>, <span class="number">0.662</span>, <span class="number">0.598</span>], [<span class="number">1</span>, <span class="number">1.791</span>, <span class="number">1.889</span>], [<span class="number">1</span>, <span class="number">0.158</span>, <span class="number">0.12</span>], [<span class="number">1</span>, <span class="number">1.55</span>, <span class="number">1.835</span>], [<span class="number">1</span>, <span class="number">2.0</span>, <span class="number">0.613</span>], [<span class="number">1</span>, <span class="number">1.176</span>, <span class="number">0.368</span>], [<span class="number">1</span>, <span class="number">0.564</span>, <span class="number">0.043</span>], [<span class="number">1</span>, <span class="number">1.559</span>, <span class="number">1.507</span>], [<span class="number">1</span>, <span class="number">1.998</span>, <span class="number">0.988</span>], [<span class="number">1</span>, <span class="number">0.082</span>, <span class="number">0.941</span>], [<span class="number">1</span>, <span class="number">0.542</span>, <span class="number">1.371</span>], [<span class="number">1</span>, <span class="number">0.542</span>, <span class="number">0.671</span>], [<span class="number">1</span>, <span class="number">1.34</span>, <span class="number">1.856</span>], [<span class="number">1</span>, <span class="number">0.049</span>, <span class="number">0.089</span>], [<span class="number">1</span>, <span class="number">1.933</span>, <span class="number">0.871</span>], [<span class="number">1</span>, <span class="number">1.753</span>, <span class="number">1.024</span>], [<span class="number">1</span>, <span class="number">0.315</span>, <span class="number">1.341</span>], [<span class="number">1</span>, <span class="number">0.829</span>, <span class="number">1.26</span>], [<span class="number">1</span>, <span class="number">0.686</span>, <span class="number">1.721</span>], [<span class="number">1</span>, <span class="number">1.222</span>, <span class="number">1.129</span>], [<span class="number">1</span>, <span class="number">0.55</span>, <span class="number">0.075</span>], [<span class="number">1</span>, <span class="number">0.767</span>, <span class="number">0.346</span>], [<span class="number">1</span>, <span class="number">1.516</span>, <span class="number">1.752</span>], [<span class="number">1</span>, <span class="number">1.347</span>, <span class="number">0.905</span>], [<span class="number">1</span>, <span class="number">0.127</span>, <span class="number">0.782</span>], [<span class="number">1</span>, <span class="number">1.169</span>, <span class="number">1.272</span>], [<span class="number">1</span>, <span class="number">1.301</span>, <span class="number">0.273</span>], [<span class="number">1</span>, <span class="number">0.081</span>, <span class="number">0.739</span>], [<span class="number">1</span>, <span class="number">0.203</span>, <span class="number">0.658</span>], [<span class="number">1</span>, <span class="number">0.347</span>, <span class="number">1.064</span>], [<span class="number">1</span>, <span class="number">0.793</span>, <span class="number">1.193</span>], [<span class="number">1</span>, <span class="number">1.428</span>, <span class="number">0.326</span>], [<span class="number">1</span>, <span class="number">0.509</span>, <span class="number">0.983</span>], [<span class="number">1</span>, <span class="number">0.12</span>, <span class="number">0.884</span>], [<span class="number">1</span>, <span class="number">0.251</span>, <span class="number">0.282</span>], [<span class="number">1</span>, <span class="number">0.73</span>, <span class="number">0.445</span>], [<span class="number">1</span>, <span class="number">1.889</span>, <span class="number">1.323</span>], [<span class="number">1</span>, <span class="number">1.314</span>, <span class="number">1.795</span>], [<span class="number">1</span>, <span class="number">1.297</span>, <span class="number">1.467</span>], [<span class="number">1</span>, <span class="number">1.669</span>, <span class="number">0.613</span>], [<span class="number">1</span>, <span class="number">0.753</span>, <span class="number">0.114</span>], [<span class="number">1</span>, <span class="number">0.94</span>, <span class="number">1.972</span>], [<span class="number">1</span>, <span class="number">0.738</span>, <span class="number">1.603</span>], [<span class="number">1</span>, <span class="number">1.508</span>, <span class="number">1.237</span>], [<span class="number">1</span>, <span class="number">0.979</span>, <span class="number">0.572</span>], [<span class="number">1</span>, <span class="number">0.128</span>, <span class="number">1.254</span>], [<span class="number">1</span>, <span class="number">0.569</span>, <span class="number">0.155</span>], [<span class="number">1</span>, <span class="number">0.88</span>, <span class="number">0.211</span>], [<span class="number">1</span>, <span class="number">0.405</span>, <span class="number">0.603</span>], [<span class="number">1</span>, <span class="number">1.02</span>, <span class="number">1.9</span>], [<span class="number">1</span>, <span class="number">0.438</span>, <span class="number">1.535</span>], [<span class="number">1</span>, <span class="number">1.506</span>, <span class="number">1.638</span>], [<span class="number">1</span>, <span class="number">1.712</span>, <span class="number">0.394</span>], [<span class="number">1</span>, <span class="number">0.556</span>, <span class="number">0.124</span>], [<span class="number">1</span>, <span class="number">0.444</span>, <span class="number">0.115</span>], [<span class="number">1</span>, <span class="number">0.595</span>, <span class="number">1.009</span>], [<span class="number">1</span>, <span class="number">0.165</span>, <span class="number">0.089</span>], [<span class="number">1</span>, <span class="number">1.57</span>, <span class="number">0.634</span>], [<span class="number">1</span>, <span class="number">1.429</span>, <span class="number">1.181</span>], [<span class="number">1</span>, <span class="number">0.8</span>, <span class="number">0.671</span>], [<span class="number">1</span>, <span class="number">1.914</span>, <span class="number">1.091</span>], [<span class="number">1</span>, <span class="number">0.594</span>, <span class="number">0.569</span>], [<span class="number">1</span>, <span class="number">0.935</span>, <span class="number">0.277</span>], [<span class="number">1</span>, <span class="number">0.47</span>, <span class="number">0.522</span>], [<span class="number">1</span>, <span class="number">0.94</span>, <span class="number">1.924</span>], [<span class="number">1</span>, <span class="number">0.194</span>, <span class="number">1.933</span>], [<span class="number">1</span>, <span class="number">0.612</span>, <span class="number">0.613</span>], [<span class="number">1</span>, <span class="number">0.236</span>, <span class="number">0.894</span>], [<span class="number">1</span>, <span class="number">1.888</span>, <span class="number">0.251</span>], [<span class="number">1</span>, <span class="number">1.548</span>, <span class="number">0.191</span>], [<span class="number">1</span>, <span class="number">1.543</span>, <span class="number">0.603</span>], [<span class="number">1</span>, <span class="number">1.521</span>, <span class="number">0.02</span>], [<span class="number">1</span>, <span class="number">0.923</span>, <span class="number">0.856</span>], [<span class="number">1</span>, <span class="number">0.649</span>, <span class="number">1.31</span>], [<span class="number">1</span>, <span class="number">0.379</span>, <span class="number">1.746</span>], [<span class="number">1</span>, <span class="number">1.345</span>, <span class="number">0.902</span>], [<span class="number">1</span>, <span class="number">0.937</span>, <span class="number">0.524</span>], [<span class="number">1</span>, <span class="number">1.018</span>, <span class="number">0.68</span>], [<span class="number">1</span>, <span class="number">1.738</span>, <span class="number">1.623</span>], [<span class="number">1</span>, <span class="number">1.534</span>, <span class="number">1.9</span>], [<span class="number">1</span>, <span class="number">0.139</span>, <span class="number">1.911</span>], [<span class="number">1</span>, <span class="number">1.508</span>, <span class="number">1.173</span>], [<span class="number">1</span>, <span class="number">0.798</span>, <span class="number">0.865</span>], [<span class="number">1</span>, <span class="number">0.451</span>, <span class="number">1.186</span>], [<span class="number">1</span>, <span class="number">1.63</span>, <span class="number">1.123</span>], [<span class="number">1</span>, <span class="number">0.82</span>, <span class="number">0.848</span>], [<span class="number">1</span>, <span class="number">1.213</span>, <span class="number">1.48</span>], [<span class="number">1</span>, <span class="number">0.894</span>, <span class="number">0.664</span>], [<span class="number">1</span>, <span class="number">1.456</span>, <span class="number">0.934</span>], [<span class="number">1</span>, <span class="number">0.59</span>, <span class="number">1.525</span>], [<span class="number">1</span>, <span class="number">0.522</span>, <span class="number">1.329</span>], [<span class="number">1</span>, <span class="number">1.179</span>, <span class="number">1.396</span>], [<span class="number">1</span>, <span class="number">0.527</span>, <span class="number">0.273</span>], [<span class="number">1</span>, <span class="number">1.399</span>, <span class="number">1.215</span>], [<span class="number">1</span>, <span class="number">0.966</span>, <span class="number">1.514</span>], [<span class="number">1</span>, <span class="number">1.341</span>, <span class="number">0.028</span>], [<span class="number">1</span>, <span class="number">0.479</span>, <span class="number">0.191</span>], [<span class="number">1</span>, <span class="number">1.193</span>, <span class="number">0.724</span>], [<span class="number">1</span>, <span class="number">0.714</span>, <span class="number">1.285</span>]]</span><br><span class="line">g_Ty_arr=[[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, <span class="number">0</span>]]</span><br><span class="line">g_y_arr=[<span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">phi</span>(<span class="params">i,theta,x</span>):</span><br><span class="line">	theta_n = <span class="built_in">len</span>(theta)</span><br><span class="line">	numerator = math.exp(np.dot(theta[i], x))</span><br><span class="line">	denominator = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(theta_n):                      <span class="comment"># maybe need to optimize</span></span><br><span class="line">		denominator = denominator + math.exp(np.dot(theta[j],x))</span><br><span class="line">	<span class="keyword">return</span> numerator/denominator</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">h_theta</span>(<span class="params">theta,x</span>):</span><br><span class="line">	theta_n = <span class="built_in">len</span>(theta)</span><br><span class="line">	ret = []</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(theta_n):</span><br><span class="line">		ret.append(phi(i,theta,x))</span><br><span class="line">	<span class="keyword">return</span> ret</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">one</span>(<span class="params">y,i</span>):</span><br><span class="line">	<span class="keyword">if</span> y == i:</span><br><span class="line">		<span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">	<span class="keyword">else</span>:</span><br><span class="line">		<span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">derl</span>(<span class="params">f,x_arr,y_arr,theta</span>):</span><br><span class="line">	<span class="comment"># 0.</span></span><br><span class="line">	<span class="comment"># f is the dimension to calc the partial derivative</span></span><br><span class="line">	<span class="comment"># 1. calc the size</span></span><br><span class="line">	<span class="comment"># theta_n is the size of theta, equals to the length of Ty&#x27; result set -1 .Here, equals lenght of &#123;0,1,2&#125; = 3-1 =2</span></span><br><span class="line">	<span class="comment"># m is the sum of samples</span></span><br><span class="line">	<span class="comment"># x_n is the dimension of the input variable &#x27;x&#x27; + 1 (for x_0 =1). Here is 2 + 1 = 3</span></span><br><span class="line">	theta_n = <span class="built_in">len</span>(theta)</span><br><span class="line">	m = <span class="built_in">len</span>(x_arr)</span><br><span class="line">	x_n = <span class="built_in">len</span>(x_arr[<span class="number">0</span>])</span><br><span class="line">	<span class="comment"># initial the output variable sum.Here is a vector, and the length of this vector is x_n</span></span><br><span class="line">	<span class="built_in">sum</span> = []</span><br><span class="line">	<span class="keyword">for</span> x_dim_index <span class="keyword">in</span> <span class="built_in">range</span>(x_n):</span><br><span class="line">			<span class="built_in">sum</span>.append(<span class="number">0</span>)</span><br><span class="line">	<span class="comment"># 2. calc the partial derivative</span></span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(x_n):</span><br><span class="line">		<span class="built_in">sum</span>[i] = <span class="number">0</span></span><br><span class="line">		<span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">			<span class="built_in">sum</span>[i]=<span class="built_in">sum</span>[i]+(one(y_arr[j],f)-phi(f,theta,x_arr[j]))*x_arr[j][i]</span><br><span class="line">		<span class="built_in">sum</span>[i]=<span class="built_in">sum</span>[i]/m</span><br><span class="line">	<span class="comment">#sum=plus_vector(sum,theta[f],0.1)</span></span><br><span class="line">	<span class="keyword">return</span> <span class="built_in">sum</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plus_vector</span>(<span class="params">arr1,arr2,a</span>):</span><br><span class="line">	<span class="keyword">return</span> [x + a * y <span class="keyword">for</span> x, y <span class="keyword">in</span> <span class="built_in">zip</span>(arr1, arr2)]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">theta,a,x_arr,y_arr</span>):</span><br><span class="line">	theta_n = <span class="built_in">len</span>(theta)</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(theta_n):</span><br><span class="line">		theta[i]=plus_vector(theta[i],derl(i, x_arr,y_arr,theta),a)</span><br><span class="line">	<span class="keyword">return</span> theta</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">judge1</span>(<span class="params">theta,x_arr,y_arr_vector,limit,debug</span>):</span><br><span class="line">	j_theta = J(theta,x_arr,y_arr_vector)</span><br><span class="line">	<span class="keyword">if</span> j_theta &lt; limit:</span><br><span class="line">		<span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">	<span class="keyword">if</span> debug:</span><br><span class="line">		<span class="built_in">print</span>(<span class="string">&quot;|J_theta(x)| = &quot;</span>, j_theta,<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">	<span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">J</span>(<span class="params">theta,x_arr,y_arr_vector</span>):</span><br><span class="line">	<span class="built_in">sum</span>=<span class="number">0</span></span><br><span class="line">	m = <span class="built_in">len</span>(x_arr)</span><br><span class="line">	y_len = <span class="built_in">len</span>(y_arr_vector[<span class="number">0</span>])</span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">		<span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(y_len):</span><br><span class="line">			<span class="built_in">sum</span> = <span class="built_in">sum</span> + (phi(j,theta,x_arr[i]) - y_arr_vector[i][j])**<span class="number">2</span></span><br><span class="line">	<span class="keyword">return</span> <span class="built_in">sum</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calTheVaule</span>():</span><br><span class="line">	<span class="comment">#theta=[[theta_1_1,theta_1_2],[theta_2_1,theta_2_2],[theta_3_1,theta_3_2]]</span></span><br><span class="line">	theta = [[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>]]</span><br><span class="line">	a = <span class="number">1</span></span><br><span class="line">	count = <span class="number">0</span></span><br><span class="line">	<span class="keyword">while</span> <span class="number">1</span>:</span><br><span class="line">		<span class="keyword">if</span> judge1(theta,g_x_arr,g_Ty_arr,<span class="number">1</span>,<span class="literal">True</span>):</span><br><span class="line">			<span class="keyword">break</span></span><br><span class="line">		theta=update(theta,a,g_x_arr,g_y_arr)</span><br><span class="line">		count = count + <span class="number">1</span></span><br><span class="line">		<span class="built_in">print</span>(<span class="string">&quot;count=&quot;</span>,count,<span class="string">&quot;theta=&quot;</span>,theta)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calcIndex</span>(<span class="params">theta,x</span>):</span><br><span class="line">  phi0 = phi(<span class="number">0</span>,theta,x)</span><br><span class="line">  phi1 = phi(<span class="number">1</span>,theta,x)</span><br><span class="line">  phi2 = phi(<span class="number">2</span>,theta,x)</span><br><span class="line">  <span class="keyword">if</span> phi0 &gt;= phi1 <span class="keyword">and</span> phi0 &gt;=phi1:</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">  <span class="keyword">elif</span> phi1&gt;= phi0 <span class="keyword">and</span> phi1 &gt;= phi2:</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">return</span> <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">testValue</span>():</span><br><span class="line">  <span class="comment"># limit =1， count = 33844</span></span><br><span class="line">  theta = [[<span class="number">17.418683742474045</span>, <span class="number">13.989348587756815</span>, -<span class="number">37.731307869980014</span>],[-<span class="number">33.56035031194091</span>, <span class="number">1.3797244978249763</span>, <span class="number">34.095843086377855</span>],[<span class="number">19.97548491920147</span>, -<span class="number">11.65484983882828</span>, <span class="number">7.628008093823735</span>]]</span><br><span class="line">  samples = <span class="number">100</span></span><br><span class="line">  figure, ax = plt.subplots()</span><br><span class="line">  <span class="comment"># 设置x，y值域</span></span><br><span class="line">  ax.set_xlim(left=<span class="number">0</span>, right=<span class="number">2</span>)</span><br><span class="line">  ax.set_ylim(bottom=<span class="number">0</span>, top=<span class="number">2</span>)</span><br><span class="line">  <span class="comment"># 两条line的数据</span></span><br><span class="line">  (line1_xs, line1_ys) = [(<span class="number">0</span>, <span class="number">2</span>), (<span class="number">0</span>, <span class="number">1</span>)]</span><br><span class="line">  (line2_xs, line2_ys) = [(<span class="number">0</span>, <span class="number">2</span>), (<span class="number">2</span>, <span class="number">1</span>)]</span><br><span class="line">  <span class="comment"># 创建两条线，并添加</span></span><br><span class="line">  ax.add_line(Line2D(line1_xs, line1_ys, linewidth=<span class="number">1</span>, color=<span class="string">&#x27;blue&#x27;</span>))</span><br><span class="line">  ax.add_line(Line2D(line2_xs, line2_ys, linewidth=<span class="number">1</span>, color=<span class="string">&#x27;blue&#x27;</span>))</span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(samples):</span><br><span class="line">    x_0 = random.randint(<span class="number">0</span>,<span class="number">2000</span>)/<span class="number">1000</span></span><br><span class="line">    x_1 = random.randint(<span class="number">0</span>,<span class="number">2000</span>)/<span class="number">1000</span></span><br><span class="line">    index = calcIndex(theta,[<span class="number">1</span>,x_0,x_1])</span><br><span class="line">    <span class="keyword">if</span> index == <span class="number">0</span>:</span><br><span class="line">      plt.plot(x_0, x_1, <span class="string">&#x27;b--&#x27;</span>, marker=<span class="string">&#x27;x&#x27;</span>, color=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    <span class="keyword">elif</span> index == <span class="number">1</span>:</span><br><span class="line">      plt.plot(x_0, x_1, <span class="string">&#x27;b--&#x27;</span>, marker=<span class="string">&#x27;+&#x27;</span>, color=<span class="string">&#x27;g&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      plt.plot(x_0, x_1, <span class="string">&#x27;b--&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, color=<span class="string">&#x27;b&#x27;</span>)</span><br><span class="line">  plt.xlabel(<span class="string">&quot;x1&quot;</span>)</span><br><span class="line">  plt.ylabel(<span class="string">&quot;x2&quot;</span>)</span><br><span class="line">  plt.plot()</span><br><span class="line">  plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__== <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">  <span class="comment">#calTheVaule()</span></span><br><span class="line">  testValue()</span><br></pre></td></tr></table></figure>

<p>经过33844次迭代之后，我们得到\(\theta\) &#x3D; [[17.418683742474045, 13.989348587756815, -37.731307869980014],[-33.56035031194091, 1.3797244978249763, 34.095843086377855],[19.97548491920147, -11.65484983882828, 7.628008093823735]]</p>
<blockquote>
<p>迭代的次数越多数据会越准确，这里迭代了上三万次，实际上可以通过牛顿法来减少迭代的次数，这里就不再重新代码了，牛顿法可以参见前面的文章。</p>
</blockquote>
<p>然后，我们随机制造一组值，看看分类效果，具体如下：</p>
<img src="/images/机器学习/监督学习-softmax计算结果.png" width=50% height=50% text-align=center/>

<h2 id="附录-公式推导手写版"><a href="#附录-公式推导手写版" class="headerlink" title="附录 公式推导手写版"></a>附录 公式推导手写版</h2><img src="/images/机器学习/监督学习-softmax公式推导手写版1.png" width=50% height=50% text-align=center/>

<img src="/images/机器学习/监督学习-softmax公式推导手写版2.png" width=50% height=50% text-align=center/>

<img src="/images/机器学习/监督学习-softmax公式推导手写版3.png" width=50% height=50% text-align=center/>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2017/07/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-2-4-%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%B9%8Bsoftmax/" data-id="cm6uj1jcl00067rrmbtdt6rl5" data-title="机器学习-2.4-监督学习之softmax" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017/08/05/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-2-5-%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%B9%8B%E7%94%9F%E6%88%90%E5%9E%8B%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          机器学习-2.5-监督学习之生成型学习算法
        
      </div>
    </a>
  
  
    <a href="/2017/07/16/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-2.3-%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%80%9A%E7%94%A8%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">机器学习-2.3-监督学习之通用线性模型</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/02/">February 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/12/">December 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/10/">October 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/09/">September 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">August 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">July 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/06/">June 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">May 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2025/02/07/2024-04-22/">(no title)</a>
          </li>
        
          <li>
            <a href="/2025/02/07/ErasuceCode%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0/">(no title)</a>
          </li>
        
          <li>
            <a href="/2023/12/25/RSS-%E8%BF%9C%E7%A8%8BMerge%E7%9A%84%E8%AE%BE%E8%AE%A1/">RSS-远程Merge的设计</a>
          </li>
        
          <li>
            <a href="/2023/12/25/RSS-%E8%BF%9C%E7%A8%8BMerge%E7%9A%84%E8%AE%BE%E8%AE%A1EN/">RSS-Remote Merge Design</a>
          </li>
        
          <li>
            <a href="/2017/10/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-3-2-%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%B9%8B%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/">机器学习-3.2-非监督学习之主成分分析.md</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2025 zhengchenyu<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>